"""
RapidAPI YouTube Downloader Integration

Uses youtube-info-download-api.p.rapidapi.com for reliable YouTube downloads.
This is the PRIMARY download method with the highest priority.
"""

import os
import logging
import asyncio
import aiohttp
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
import json

logger = logging.getLogger(__name__)


async def download_youtube_video_rapidapi(url: str, output_dir: Path) -> Tuple[Optional[str], Optional[str], Optional[Dict[str, Any]]]:
    """
    Download YouTube video using RapidAPI YouTube Info Download API.
    This is the TIER 0 (highest priority) download method.
    
    Args:
        url: YouTube video URL
        output_dir: Directory to save the video
        
    Returns:
        tuple: (file_path, title, video_info)
    """
    try:
        logger.info(f"üöÄ [TIER 0] Starting RapidAPI YouTube download")
        logger.info(f"   URL: {url}")
        logger.info(f"   Output dir: {output_dir}")
        
        # Get API key from environment
        api_key = os.getenv("RAPIDAPI_YOUTUBE_KEY")
        if not api_key:
            logger.error("‚ùå RAPIDAPI_YOUTUBE_KEY not found in environment")
            return None, None, None
        
        logger.info(f"   API key configured: {api_key[:10]}...")
        
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"‚úÖ Output directory ready: {output_dir}")
        
        # Step 1: Get download info from RapidAPI
        logger.info(f"üì° Requesting download info from RapidAPI...")
        download_info = await _get_download_info(url, api_key)
        
        if not download_info:
            logger.error("‚ùå Failed to get download info from RapidAPI")
            return None, None, None
        
        logger.info(f"‚úÖ Received download info from RapidAPI")
        logger.info(f"   Title: {download_info.get('title', 'Unknown')}")
        logger.info(f"   Duration: {download_info.get('duration', 'Unknown')}")
        
        # Step 2: Download the video file
        video_url = download_info.get('video_url')
        if not video_url:
            logger.error("‚ùå No video download URL in response")
            return None, None, None
        
        logger.info(f"‚¨áÔ∏è  Downloading video file...")
        file_path = await _download_file(video_url, output_dir, download_info.get('title', 'video'))
        
        if not file_path:
            logger.error("‚ùå Failed to download video file")
            return None, None, None
        
        logger.info(f"‚úÖ RapidAPI download complete: {file_path}")
        
        # Prepare video info
        video_info = {
            'title': download_info.get('title'),
            'duration': download_info.get('duration'),
            'thumbnail': download_info.get('thumbnail'),
            'channel': download_info.get('channel'),
            'source': 'rapidapi'
        }
        
        return file_path, download_info.get('title'), video_info
        
    except Exception as e:
        logger.error(f"‚ùå Error in RapidAPI YouTube download")
        logger.error(f"   Error type: {type(e).__name__}")
        logger.error(f"   Error message: {str(e)}")
        logger.exception("Full stack trace:")
        return None, None, None


async def _get_download_info(url: str, api_key: str) -> Optional[Dict[str, Any]]:
    """
    Get download information from RapidAPI.
    
    Args:
        url: YouTube video URL
        api_key: RapidAPI key
        
    Returns:
        Dict with download info or None if failed
    """
    try:
        # RapidAPI endpoint
        api_url = "https://youtube-info-download-api.p.rapidapi.com/ajax/download.php"
        
        # Try multiple format options in order of preference (highest quality first)
        format_options = [
            {'format': '1080', 'add_info': '1'},  # Try 1080p quality (HIGHEST)
            {'format': '720', 'add_info': '1'},   # Try 720p quality
            {'format': '480', 'add_info': '1'},   # Try 480p quality
            {'format': '360', 'add_info': '1'},   # Try 360p quality
        ]
        
        headers = {
            'x-rapidapi-host': 'youtube-info-download-api.p.rapidapi.com',
            'x-rapidapi-key': api_key
        }
        
        last_error = None
        
        # Try each format until one works
        for format_idx, format_config in enumerate(format_options):
            # Add delay between format attempts to avoid rate limiting
            if format_idx > 0:
                delay = 2 * format_idx  # 2s, 4s, 6s delays
                logger.info(f"‚è≥ Waiting {delay}s before trying next format...")
                await asyncio.sleep(delay)
            
            # Retry each format up to 2 times
            for retry in range(2):
                try:
                    if retry > 0:
                        wait_time = 3 * retry  # 3s backoff for retry
                        logger.info(f"üîÑ Retry {retry + 1}/2 for format {format_config.get('format')} after {wait_time}s...")
                        await asyncio.sleep(wait_time)
                    
                    params = {
                        'url': url,
                        'no_merge': 'false',
                        'allow_extended_duration': 'true',
                        **format_config
                    }
                    
                    logger.info(f"üìã RapidAPI request parameters:")
                    logger.info(f"   Format: {format_config.get('format')}")
                    logger.info(f"   URL: {url}")
                    
                    # Make async request with longer timeout for AWS deployment
                    timeout = aiohttp.ClientTimeout(total=120, connect=60)
                    async with aiohttp.ClientSession(timeout=timeout) as session:
                        async with session.get(api_url, params=params, headers=headers) as response:
                            logger.info(f"üì° RapidAPI response status: {response.status}")
                            
                            if response.status == 200:
                                # Parse response
                                data = await response.json()
                                logger.info(f"‚úÖ RapidAPI response received for format {format_config.get('format')}")
                                
                                # This API returns HTML content, not direct download links
                                # We need to use the progress_url to get the actual download link
                                if data.get('success') and 'progress_url' in data:
                                    progress_url = data['progress_url']
                                    logger.info(f"üì° Polling progress URL to get download link: {progress_url}")
                                    
                                    # Poll the progress URL to get the actual download link
                                    download_url = await _poll_progress_url(progress_url, api_key)
                                    
                                    if download_url:
                                        logger.info(f"‚úÖ Found download URL with format {format_config.get('format')}: {download_url[:100]}...")
                                        return {
                                            'video_url': download_url,
                                            'title': data.get('title', 'Unknown'),
                                            'duration': data.get('info', {}).get('duration'),
                                            'thumbnail': data.get('info', {}).get('thumbnail'),
                                            'channel': data.get('info', {}).get('channel') or data.get('info', {}).get('uploader')
                                        }
                                    else:
                                        logger.warning(f"‚ö†Ô∏è Format {format_config.get('format')}: Failed to get download URL from progress endpoint")
                                else:
                                    logger.warning(f"‚ö†Ô∏è Format {format_config.get('format')}: No progress_url in response")
                                    logger.warning(f"   Response keys: {list(data.keys())}")
                                    if data.get('error'):
                                        logger.warning(f"   API error: {data.get('error')}")
                                    
                            elif response.status == 429:
                                # Rate limited - wait longer
                                logger.warning(f"‚ö†Ô∏è Rate limited (429)! Waiting 10s before retry...")
                                await asyncio.sleep(10)
                                continue
                            else:
                                error_text = await response.text()
                                logger.warning(f"‚ö†Ô∏è Format {format_config.get('format')} returned {response.status}: {error_text[:200]}")
                                # Don't retry on 4xx errors (except 429), just try next format
                                if 400 <= response.status < 500 and response.status != 429:
                                    break
                                            
                except asyncio.TimeoutError:
                    logger.warning(f"‚ö†Ô∏è Timeout trying format {format_config.get('format')} (attempt {retry + 1}/2)")
                    last_error = "Request timeout"
                    continue
                except aiohttp.ClientConnectionError as e:
                    logger.warning(f"‚ö†Ô∏è Connection error trying format {format_config.get('format')}: {type(e).__name__}")
                    last_error = f"Connection error: {type(e).__name__}"
                    continue
                except Exception as format_error:
                    error_type = type(format_error).__name__
                    error_msg = str(format_error) or "No error message"
                    logger.warning(f"‚ö†Ô∏è Error trying format {format_config.get('format')}: [{error_type}] {error_msg}")
                    last_error = f"{error_type}: {error_msg}"
                    continue
                
                # If we got here without continuing, break out of retry loop
                break
        
        # If all formats failed
        logger.error(f"‚ùå All format options failed for RapidAPI download")
        if last_error:
            logger.error(f"   Last error: {last_error}")
        return None
                    
    except asyncio.TimeoutError:
        logger.error(f"‚ùå RapidAPI request timed out after 60 seconds")
        return None
    except Exception as e:
        logger.error(f"‚ùå Error getting download info from RapidAPI: [{type(e).__name__}] {str(e)}")
        logger.exception("Full stack trace:")
        return None


async def _poll_progress_url(progress_url: str, api_key: str, max_attempts: int = 10) -> Optional[str]:
    """
    Poll the progress URL to get the actual download link.
    
    Args:
        progress_url: The progress URL from initial response
        api_key: RapidAPI key
        max_attempts: Maximum polling attempts
        
    Returns:
        Direct download URL or None
    """
    try:
        headers = {
            'x-rapidapi-host': 'youtube-info-download-api.p.rapidapi.com',
            'x-rapidapi-key': api_key
        }
        
        async with aiohttp.ClientSession() as session:
            for attempt in range(max_attempts):
                await asyncio.sleep(2)  # Wait 2 seconds between polls
                
                async with session.get(progress_url, headers=headers, timeout=10) as response:
                    if response.status == 200:
                        progress_data = await response.json()
                        
                        # Check if download is ready
                        if progress_data.get('download_url'):
                            logger.info(f"‚úÖ Download URL ready after {attempt + 1} attempts")
                            return progress_data['download_url']
                        elif progress_data.get('progress') == 100 or progress_data.get('status') == 'finished':
                            # Check different possible fields for the download URL
                            url = (progress_data.get('download_url') or 
                                   progress_data.get('url') or 
                                   progress_data.get('link'))
                            if url:
                                logger.info(f"‚úÖ Download URL ready after {attempt + 1} attempts")
                                return url
                        
                        logger.info(f"‚è≥ Progress check {attempt + 1}/{max_attempts}: {progress_data.get('progress', 'N/A')}%")
                    else:
                        logger.warning(f"‚ö†Ô∏è Progress URL returned status {response.status}")
            
            logger.error(f"‚ùå Failed to get download URL after {max_attempts} polling attempts")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Error polling progress URL: {str(e)}")
        return None


async def _download_file(url: str, output_dir: Path, title: str) -> Optional[str]:
    """
    Download video file from URL.
    
    Args:
        url: Direct download URL
        output_dir: Directory to save file
        title: Video title for filename
        
    Returns:
        Path to downloaded file or None if failed
    """
    try:
        # Sanitize filename
        import re
        safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)
        safe_title = safe_title[:100]  # Limit length
        
        file_path = output_dir / f"{safe_title}.mp4"
        
        logger.info(f"‚¨áÔ∏è  Downloading to: {file_path}")
        
        # Download with progress
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=600)) as response:
                if response.status != 200:
                    logger.error(f"‚ùå Download failed with status {response.status}")
                    return None
                
                # Get file size
                file_size = int(response.headers.get('content-length', 0))
                logger.info(f"   File size: {file_size / (1024*1024):.2f} MB")
                
                # Download in chunks
                downloaded = 0
                chunk_size = 1024 * 1024  # 1MB chunks
                
                with open(file_path, 'wb') as f:
                    async for chunk in response.content.iter_chunked(chunk_size):
                        f.write(chunk)
                        downloaded += len(chunk)
                        
                        # Log progress every 10MB
                        if downloaded % (10 * 1024 * 1024) < chunk_size:
                            progress = (downloaded / file_size * 100) if file_size > 0 else 0
                            logger.info(f"   Progress: {downloaded / (1024*1024):.1f} MB ({progress:.1f}%)")
                
                logger.info(f"‚úÖ Download complete: {file_path}")
                return str(file_path)
                
    except Exception as e:
        logger.error(f"‚ùå Error downloading file: {str(e)}")
        logger.exception("Full stack trace:")
        return None
